{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch gymnasium ale-py stable-baselines3 tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import DQN\n",
    "from torch.optim import RMSprop\n",
    "from stable_baselines3.common.atari_wrappers import NoopResetEnv\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "import ale_py\n",
    "\n",
    "# Create the environment\n",
    "def make_env():\n",
    "    def _init():\n",
    "        env = gym.make(\"ALE/Breakout-v5\", render_mode=\"rgb_array\")\n",
    "        env = NoopResetEnv(env, noop_max=30)  # Add the No-op wrapper\n",
    "        env = Monitor(env)\n",
    "        return env\n",
    "    return _init\n",
    "\n",
    "env = DummyVecEnv([make_env() for _ in range(1)])\n",
    "\n",
    "\n",
    "# Initialize the DQN model\n",
    "model = DQN(\n",
    "    \"CnnPolicy\",        # Use a convolutional network policy\n",
    "    env,\n",
    "    learning_rate=0.00025,       # Standard learning rate for DQN\n",
    "    buffer_size=100000,           # Smaller replay buffer for basic DQN\n",
    "    learning_starts=2000,          # Start learning after 1,000 steps\n",
    "    batch_size=32,                  # Training batch size\n",
    "    gamma=0.99,                      # Discount factor for future rewards\n",
    "    train_freq=4,                   # Train the model every 4 steps\n",
    "    target_update_interval=10000,  # Update the target network every 1,000 steps\n",
    "    exploration_fraction=0.1,     # Fraction of steps to explore\n",
    "    exploration_final_eps=0.1,   # Final epsilon for exploration\n",
    "    verbose=1,\n",
    "    tensorboard_log=\"./dqn_logs/\",  # Path for TensorBoard logs\n",
    "    device=\"cuda\",\n",
    ")\n",
    "\n",
    "# Define the optimiser\n",
    "model.policy.optimizer = RMSprop(\n",
    "    model.policy.parameters(),\n",
    "    lr=0.00025,\n",
    "    alpha=0.95,       # Equivalent to squared gradient momentum\n",
    "    momentum=0.95,    # Gradient momentum\n",
    "    eps=0.01,         # Prevent division by zero\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.learn(total_timesteps=2000000) \n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"dqn_breakout\")\n",
    "\n",
    "# Close the environment\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnasium.wrappers import RecordVideo\n",
    "import os\n",
    "\n",
    "# Load the trained model\n",
    "loaded_model = DQN.load(\"dqn_breakout\")\n",
    "\n",
    "\n",
    "# Create the environment and wrap it for video recording\n",
    "def make_env():\n",
    "    def _init():\n",
    "        env = gym.make(\"ALE/Breakout-v5\", render_mode=\"rgb_array\")\n",
    "        env = NoopResetEnv(env, noop_max=30)  # Add No-op wrapper\n",
    "        env = Monitor(env)                   # Add Monitor wrapper for logging\n",
    "        env = RecordVideo(env, video_folder=video_folder, episode_trigger=lambda x: x == 0)  # Record the first episode\n",
    "        return env\n",
    "    return _init\n",
    "\n",
    "\n",
    "env = make_env()()\n",
    "\n",
    "video_folder = \"./videos/\"\n",
    "env = RecordVideo(env, video_folder=video_folder, episode_trigger=lambda x: x == 0)  # Record the first episode\n",
    "\n",
    "# Reset the environment and press FIRE to start the game\n",
    "obs, _ = env.reset()\n",
    "obs, reward, terminated, truncated, info = env.step(1)  # Press 'FIRE' action to start\n",
    "if terminated or truncated:\n",
    "    obs, _ = env.reset()\n",
    "\n",
    "# Play one episode and record the video\n",
    "done = False\n",
    "while not done:\n",
    "    action, _ = loaded_model.predict(obs, deterministic=True)  # Predict the action\n",
    "    obs, reward, terminated, truncated, info = env.step(action)  # Step the environment\n",
    "    done = terminated or truncated  # Check if the game is over\n",
    "\n",
    "# Close the environment\n",
    "env.close()\n",
    "print(f\"Video saved to: {video_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 46733), started 0:02:11 ago. (Use '!kill 46733' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-6f3a5e5046ff1965\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-6f3a5e5046ff1965\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./dqn_basic_logs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
